{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MShirazAhmad/toolbox/blob/main/python/nanoindentation/Nanoindentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this code block to download sample file named \"Silica.xls\"\n",
        "\n",
        "!wget https://raw.githubusercontent.com/MShirazAhmad/toolbox/refs/heads/main/python/nanoindentation/Silica.xls"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WiKhy1Wcdjrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write xls name below\n"
      ],
      "metadata": {
        "id": "c4ZqOmmKjfxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFQHXKmkC1bQ"
      },
      "outputs": [],
      "source": [
        "filename = \"Silica.xls\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhoKZTSZDUg6"
      },
      "source": [
        "# Calculating Offsets based on loading curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3hETIC3DWzR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 1: Run this codeblock\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"nano_offset_plotter_refactored.py — Compute x-offsets for nano-indentation curves (dual backend)\n",
        "==============================================================================================\n",
        "* Moving-average smoothing of the *Load* signal (default 200 pts).\n",
        "* Quadratic fit of the smoothed loading branch with optional x-cutoff (nm).\n",
        "* Plotting backends: interactive **Plotly** (default) or static **Matplotlib** via `backend` argument.\n",
        "* Function API (`collect_offsets`) and CLI.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "# Plotting libs\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as mpl\n",
        "\n",
        "# Defaults\n",
        "DEFAULT_WINDOW = 0         # moving-average window (pts)\n",
        "DEFAULT_CUTOFF = 0         # nm (≤0 ⇒ full branch)\n",
        "DEFAULT_BACKEND = \"plotly\" # or \"mpl\"\n",
        "PLOTLY_TEMPLATE = \"plotly_white\"\n",
        "\n",
        "# Helpers\n",
        "def moving_average(a: np.ndarray, window: int = DEFAULT_WINDOW) -> np.ndarray:\n",
        "    if window < 2 or len(a) < window:\n",
        "        return a\n",
        "    return np.convolve(a, np.ones(window) / window, mode=\"same\")\n",
        "\n",
        "def compute_x_offset(\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    *,\n",
        "    max_x: Optional[float] = DEFAULT_CUTOFF,\n",
        "    window: int = DEFAULT_WINDOW\n",
        ") -> Tuple[float, str]:\n",
        "    # Identify loading branch (up to peak load)\n",
        "    peak_idx = np.argmax(y)\n",
        "    x_load = x[:peak_idx + 1]\n",
        "    y_load = y[:peak_idx + 1]\n",
        "\n",
        "    # Apply cutoff if specified\n",
        "    mask = (x_load <= max_x) if (max_x and max_x > 0) else np.ones_like(x_load, bool)\n",
        "    x_fit = x_load[mask]\n",
        "    y_fit = moving_average(y_load, window)[mask]\n",
        "\n",
        "    # 1. Fit cubic polynomial\n",
        "    coeffs = np.polyfit(x_fit, y_fit, 2)\n",
        "    # 2. Evaluate the polynomial at the data points\n",
        "    y_pred = np.polyval(coeffs, x_fit)\n",
        "\n",
        "    # 3. Compute residual and total sums of squares\n",
        "    ss_res = np.sum((y_fit - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y_fit - np.mean(y_fit)) ** 2)\n",
        "\n",
        "    # 4. Coefficient of determination (R²)\n",
        "    r_squared = 1 - ss_res / ss_tot\n",
        "    # 5. Pearson correlation coefficient (r)\n",
        "    r = np.corrcoef(y_fit, y_pred)[0, 1]\n",
        "\n",
        "    r2_str = f\"R²={r_squared:.4f}, r={r:.4f}\"\n",
        "    print(r2_str)\n",
        "\n",
        "    # 6. Roots → real → within range → choose closest to zero\n",
        "    roots = np.roots(coeffs)\n",
        "    real_roots = roots[np.isreal(roots)].real\n",
        "    xmin, xmax = x_fit.min(), x_fit.max()\n",
        "    valid_roots = [rt for rt in real_roots if xmin <= rt <= xmax]\n",
        "    x_intercept = float(valid_roots[0] if valid_roots else min(real_roots, key=abs))\n",
        "\n",
        "    return x_intercept, r2_str\n",
        "\n",
        "def load_test_data(fname: str, tno: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(fname, sheet_name=f\"Test {tno}\").drop(index=[0, 1])\n",
        "    df[\"Displacement Into Surface\"] = pd.to_numeric(df[\"Displacement Into Surface\"], errors=\"coerce\")\n",
        "    df[\"Load On Sample\"]           = pd.to_numeric(df[\"Load On Sample\"], errors=\"coerce\")\n",
        "    return df.dropna(subset=[\"Displacement Into Surface\", \"Load On Sample\"])\n",
        "\n",
        "# Unified plotting function\n",
        "def plot_curves(\n",
        "    dataset: List[Tuple[pd.DataFrame, str, float, str]],\n",
        "    *,\n",
        "    window: int,\n",
        "    cutoff: Optional[float],\n",
        "    backend: str = DEFAULT_BACKEND,\n",
        "    plot_mode: str = \"separate\",\n",
        "    fname: str\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plot nanoindentation curves using Plotly or Matplotlib, in separate or combined mode.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset    : List of (DataFrame, test_number, x_offset, r2_str) tuples\n",
        "    window     : Moving-average window length (points)\n",
        "    cutoff     : Fit only x ≤ cutoff nm; <=0 or None → full curve\n",
        "    backend    : 'plotly' or 'mpl'\n",
        "    plot_mode  : 'separate' or 'combined'\n",
        "    fname      : source Excel filename (for HTML export)\n",
        "    \"\"\"\n",
        "    if not dataset:\n",
        "        return\n",
        "\n",
        "    fit_tag = \"full\" if not cutoff or cutoff <= 0 else f\"≤{cutoff:g} nm\"\n",
        "    fig = go.Figure()\n",
        "    palette = px.colors.qualitative.Plotly * 6\n",
        "\n",
        "    for idx, (df, tno, x_off, r2_str) in enumerate(dataset):\n",
        "        df = df.copy()\n",
        "        df[\"Displacement Into Surface\"] -= x_off\n",
        "        peak = df[\"Load On Sample\"].idxmax()\n",
        "        dfL, dfU = df.iloc[:peak+1], df.iloc[peak+1:]\n",
        "\n",
        "        # Cutoff-aware fit on loading branch\n",
        "        if cutoff and cutoff > 0:\n",
        "            maskL = dfL[\"Displacement Into Surface\"] <= cutoff\n",
        "            x_plot_max = cutoff\n",
        "        else:\n",
        "            maskL = np.ones(len(dfL), bool)\n",
        "            x_plot_max = dfL[\"Displacement Into Surface\"].max()\n",
        "\n",
        "        # Plot raw data\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=dfL[\"Displacement Into Surface\"],\n",
        "            y=dfL[\"Load On Sample\"],\n",
        "            mode=\"markers\",\n",
        "            marker=dict(symbol=\"circle-open\", color=palette[idx], opacity=0.2),\n",
        "            name=f\"Test {tno} ({r2_str})\"\n",
        "        ))\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=dfU[\"Displacement Into Surface\"],\n",
        "            y=dfU[\"Load On Sample\"],\n",
        "            mode=\"markers\",\n",
        "            marker=dict(symbol=\"circle-open\", color=palette[idx], opacity=0.2),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "        # Fitted curve\n",
        "        x_fitL = dfL[\"Displacement Into Surface\"][maskL]\n",
        "        y_fitL = moving_average(dfL[\"Load On Sample\"], window)[maskL]\n",
        "        cL = np.polyfit(x_fitL, y_fitL, 2)\n",
        "        xL = np.linspace(0, x_plot_max, 200)\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=xL,\n",
        "            y=np.polyval(cL, xL),\n",
        "            mode=\"lines\",\n",
        "            line=dict(color=palette[idx]),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            template=PLOTLY_TEMPLATE,\n",
        "            # title=f\"Combined plots ({window}-pt avg, fit: {fit_tag})\",\n",
        "            xaxis=dict(range=[0, None], title=\"Displacement / nm\", tickformat=\"02d\"),\n",
        "            yaxis=dict(range=[0, None], title=\"Load / mN\"),\n",
        "            legend=dict(\n",
        "                orientation=\"h\",      # horizontal legend\n",
        "                yanchor=\"bottom\",     # anchor legend at its bottom\n",
        "                y=1.02,               # place it just above the top of the plot\n",
        "                xanchor=\"center\",     # anchor legend at its center\n",
        "                x=0.5                 # center the legend horizontally\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    # Save interactive HTML\n",
        "    base_name = os.path.splitext(os.path.basename(fname))[0]\n",
        "    html_filename = f\"Offsets_{base_name}.html\"\n",
        "    fig.write_html(html_filename, include_plotlyjs=\"cdn\")\n",
        "    print(f\"Saved interactive plot to {html_filename}\")\n",
        "\n",
        "def collect_offsets(\n",
        "    fname: str,\n",
        "    *,\n",
        "    first: int = 1,\n",
        "    last: int = 1,\n",
        "    plot_mode: str = \"separate\",\n",
        "    backend: str = \"plotly\",\n",
        "    window: int = 50,\n",
        "    cutoff_nm: Optional[float] = DEFAULT_CUTOFF,\n",
        ") -> Dict[str, Tuple[float, str]]:\n",
        "    \"\"\"\n",
        "    Batch-process Test sheets and return a dict of (offset, R² string).\n",
        "    \"\"\"\n",
        "    offsets: Dict[str, Tuple[float, str]] = {}\n",
        "    combined: List[Tuple[pd.DataFrame, str, float, str]] = []\n",
        "\n",
        "    for n in range(first, last + 1):\n",
        "        tno = f\"{n:03d}\"\n",
        "        try:\n",
        "            df = load_test_data(fname, tno)\n",
        "            off, r2_str = compute_x_offset(\n",
        "                df[\"Displacement Into Surface\"].to_numpy(),\n",
        "                df[\"Load On Sample\"].to_numpy(),\n",
        "                max_x=cutoff_nm,\n",
        "                window=window,\n",
        "            )\n",
        "            offsets[tno] = (off, r2_str)\n",
        "            print(f\"Test {tno}: x_offset={off:.3f} nm, {r2_str}\")\n",
        "\n",
        "            if plot_mode in (\"separate\", \"combined\"):\n",
        "                combined.append((df, tno, off, r2_str))\n",
        "        except Exception as e:\n",
        "            print(f\"Test {tno}: {e}\")\n",
        "\n",
        "    if plot_mode in (\"separate\", \"combined\") and combined:\n",
        "        plot_curves(\n",
        "            combined,\n",
        "            window=window,\n",
        "            cutoff=cutoff_nm,\n",
        "            backend=backend,\n",
        "            plot_mode=plot_mode,\n",
        "            fname=fname\n",
        "        )\n",
        "\n",
        "    return offsets\n",
        "\n",
        "def save_offsets(offsets: Dict[str, Tuple[float, str]], filename: str) -> None:\n",
        "    \"\"\"Save offsets and R² to a CSV file\"\"\"\n",
        "    csv_fn = f\"{filename}_offsets.csv\"\n",
        "    with open(csv_fn, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Test\", \"x_offset_nm\", \"R_squared\"])\n",
        "        for tno, (off, r2_str) in offsets.items():\n",
        "            writer.writerow([tno, f\"{off:.6f}\", r2_str])\n",
        "    print(f\"Saved offsets and R² to {csv_fn}\")\n",
        "\n",
        "\n",
        "# save_offsets(offsets, filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this codeblock to generate and save offsets csv\n",
        "\n",
        "offsets = collect_offsets(\n",
        "    filename,\n",
        "    first=1,\n",
        "    last=40,\n",
        "    window=20,\n",
        "    cutoff_nm=1000,\n",
        ")\n",
        "save_offsets(offsets, filename)"
      ],
      "metadata": {
        "id": "5lhq5vORNqRe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Graph for Manuscript"
      ],
      "metadata": {
        "id": "XAR0w0_LVJMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1: Run this code block\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Global Styling ---\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": (8, 6),\n",
        "    \"font.size\": 14,\n",
        "    \"axes.linewidth\": 1.5,\n",
        "    \"lines.linewidth\": 2.5,\n",
        "    \"font.family\": \"sans-serif\",\n",
        "    \"axes.prop_cycle\": plt.cycler(color=[\n",
        "        \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\",\n",
        "        \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\",\n",
        "        \"#bcbd22\", \"#17becf\"\n",
        "    ]),\n",
        "    \"path.simplify_threshold\": 0.0,\n",
        "    \"agg.path.chunksize\": 10000,\n",
        "})\n",
        "\n",
        "def read_combined_excel(filename, test_numbers, x_pattern, hardness_pattern):\n",
        "    combined_df = pd.DataFrame()\n",
        "    for i in test_numbers:\n",
        "        sheet = f\"Test {str(i).zfill(3)}\"\n",
        "        try:\n",
        "            df = pd.read_excel(filename, sheet_name=sheet, dtype=str, engine='xlrd')\n",
        "            df.columns = [\n",
        "                'Segment',\n",
        "                f'{x_pattern} - {i}',\n",
        "                f'Load On Sample (mN) - {i}',\n",
        "                f'Time On Sample (s) - {i}',\n",
        "                f'Harmonic Contact Stiffness (N/m) - {i}',\n",
        "                f'{hardness_pattern} - {i}',\n",
        "                f'Modulus (GPa) - {i}'\n",
        "            ]\n",
        "            df = df.drop(columns=['Segment'])\n",
        "            combined_df = pd.concat([combined_df, df], axis=1) if not combined_df.empty else df\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading sheet '{sheet}': {e}\")\n",
        "    return combined_df\n",
        "\n",
        "# --- Stats with Inf/NaN Filtering ---\n",
        "def calculate_mean_std_count(df, patterns):\n",
        "    cols = [c for c in df.columns if any(p in c for p in patterns)]\n",
        "    numeric = df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "    mean = numeric.mean(axis=1)\n",
        "    std  = numeric.std(axis=1, ddof=1)\n",
        "    cnt  = numeric.count(axis=1)\n",
        "    mean.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    std.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return mean, std, cnt\n",
        "\n",
        "# --- Weighted Propagation ---\n",
        "def propagate_weighted_average_and_uncertainty(vals, sds, cnts):\n",
        "    vals = np.asarray(vals, dtype=np.float64)\n",
        "    sds  = np.asarray(sds, dtype=np.float64)\n",
        "    cnts = np.asarray(cnts, dtype=np.float64)\n",
        "\n",
        "    # Filter only rows with finite values\n",
        "    mask = np.isfinite(vals) & np.isfinite(sds) & np.isfinite(cnts)\n",
        "    vals, sds, cnts = vals[mask], sds[mask], cnts[mask]\n",
        "\n",
        "    if len(vals) == 0 or cnts.sum() == 0:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    # --- Force-safe values ---\n",
        "    sds = np.clip(sds, 0, 100)           # Clamp to avoid overflow\n",
        "    cnts = np.clip(cnts, 1e-3, 1e5)      # Avoid zero-division\n",
        "    w = cnts / cnts.sum()\n",
        "    w = np.clip(w, 0, 1)\n",
        "\n",
        "    # --- Compute mean ---\n",
        "    mean = np.dot(w, vals)\n",
        "\n",
        "    # --- Compute variance safely ---\n",
        "    safe_var_terms = (w**2) * (sds**2)\n",
        "    if np.any(~np.isfinite(safe_var_terms)):\n",
        "        safe_var_terms = np.nan_to_num(safe_var_terms, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    var = np.sum(safe_var_terms)\n",
        "    return mean, np.sqrt(var)\n",
        "\n",
        "\n",
        "\n",
        "# --- Plot Helper ---\n",
        "def plot_curve_with_errors(ax, x, y, yerr, idx, color, label, marker):\n",
        "    mask = np.isfinite(x) & np.isfinite(y) & np.isfinite(yerr)\n",
        "    x_f, y_f, e_f = map(lambda s: pd.Series(s, dtype=np.float64), (x[mask], y[mask], yerr[mask]))\n",
        "    ax.plot(x_f, y_f, color=color, label=label, linewidth=2.5)\n",
        "    if isinstance(idx, (list, np.ndarray)):\n",
        "        for i in idx:\n",
        "            if i < len(x_f):\n",
        "                ax.errorbar(x_f.iloc[i], y_f.iloc[i], yerr=e_f.iloc[i], fmt=marker,\n",
        "                            markersize=6, linestyle='none', capsize=3,\n",
        "                            color=color, linewidth=1.5)\n",
        "    else:\n",
        "        if idx < len(x_f):\n",
        "            ax.errorbar(x_f.iloc[idx], y_f.iloc[idx], yerr=e_f.iloc[idx], fmt=marker,\n",
        "                        markersize=6, linestyle='none', capsize=3,\n",
        "                        color=color, linewidth=1.5)\n",
        "\n",
        "# --- Main Comparison ---\n",
        "def compare_files_with_weighted_uncertainty(\n",
        "    file_configs,\n",
        "    x_pattern,\n",
        "    hardness_pattern,\n",
        "    modulus_pattern,\n",
        "    target_x_range,\n",
        "    hardness_ylim,\n",
        "    modulus_ylim\n",
        "):\n",
        "    x_min, x_max, step = target_x_range\n",
        "    h_min, h_max = hardness_ylim\n",
        "    m_min, m_max = modulus_ylim\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(\n",
        "        2, 1, figsize=(8, 6), sharex=True,\n",
        "        gridspec_kw={'hspace': 0.05}, constrained_layout=True\n",
        "    )\n",
        "\n",
        "    for cfg in file_configs:\n",
        "        df = read_combined_excel(cfg['filename'], cfg['test_numbers'], x_pattern, hardness_pattern)\n",
        "        if df.empty:\n",
        "            continue\n",
        "        x_col = next((c for c in df.columns if x_pattern in c), None)\n",
        "        x = pd.to_numeric(df[x_col], errors='coerce')\n",
        "\n",
        "        m_h, s_h, c_h = calculate_mean_std_count(df, [hardness_pattern])\n",
        "        m_m, s_m, c_m = calculate_mean_std_count(df, [modulus_pattern])\n",
        "\n",
        "        mask_h = (x >= x_min) & (x <= x_max) & (m_h >= h_min) & (m_h <= h_max)\n",
        "        mask_m = (x >= x_min) & (x <= x_max) & (m_m >= m_min) & (m_m <= m_max)\n",
        "\n",
        "        # Hardness\n",
        "        if mask_h.any():\n",
        "            idxs_h = [abs(x[mask_h] - v).argmin() for v in np.arange(x_min, x_max, step)]\n",
        "            plot_curve_with_errors(ax1, x[mask_h], m_h[mask_h], s_h[mask_h], idxs_h,\n",
        "                                   cfg['hardness_color'], cfg['label'], 'o')\n",
        "            avg_h, err_h = propagate_weighted_average_and_uncertainty(m_h[mask_h], s_h[mask_h], c_h[mask_h])\n",
        "            print(f\"{cfg['label']} - Weighted Mean Hardness: {avg_h:.2f} ± {err_h:.2f} GPa\")\n",
        "        else:\n",
        "            print(f\"{cfg['label']} - No hardness data within specified limits, skipping.\")\n",
        "\n",
        "        # Modulus\n",
        "        if mask_m.any():\n",
        "            idxs_m = [abs(x[mask_m] - v).argmin() for v in np.arange(x_min, x_max, step)]\n",
        "            plot_curve_with_errors(ax2, x[mask_m], m_m[mask_m], s_m[mask_m], idxs_m,\n",
        "                                   cfg['modulus_color'], cfg['label'], 's')\n",
        "            avg_m, err_m = propagate_weighted_average_and_uncertainty(m_m[mask_m], s_m[mask_m], c_m[mask_m])\n",
        "            print(f\"{cfg['label']} - Weighted Mean Modulus: {avg_m:.2f} ± {err_m:.2f} GPa\\n\")\n",
        "        else:\n",
        "            print(f\"{cfg['label']} - No modulus data within specified limits, skipping.\\n\")\n",
        "\n",
        "    for ax in (ax1, ax2):\n",
        "        ax.minorticks_on()\n",
        "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "    ax1.set_xlim(x_min, x_max)\n",
        "    ax1.set_ylim(h_min, h_max)\n",
        "    ax1.set_ylabel(hardness_pattern)\n",
        "\n",
        "    ax2.set_xlim(x_min, x_max)\n",
        "    ax2.set_ylim(m_min, m_max)\n",
        "    ax2.set_xlabel(x_pattern)\n",
        "    ax2.set_ylabel(modulus_pattern)\n",
        "\n",
        "    # Legend guard\n",
        "    handles, labels = ax1.get_legend_handles_labels()\n",
        "    if labels:\n",
        "        fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.99),\n",
        "                   ncol=len(labels), frameon=False)\n",
        "\n",
        "    fig.savefig(\"comparison_with_weighted_uncertainty.png\", dpi=300)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "b1YkYuPLVK9P",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#title Graph Configs\n",
        "\n",
        "file_configs_single = [\n",
        "    {\n",
        "        'filename': filename,\n",
        "        'test_numbers': [1, 2, 3, 4, 5],  # All tests for this sample\n",
        "        'label': 'My Material Sample',\n",
        "        'hardness_color': '#1f77b4',  # Blue\n",
        "        'modulus_color': '#1f77b4',   # Blue\n",
        "        'offset_csv': 'Silica.xls_offsets.csv'  # Optional: correct depth offsets\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run the comparison for single sample\n",
        "compare_files_with_weighted_uncertainty(\n",
        "    file_configs=file_configs_single,\n",
        "    x_pattern='Depth (nm)',           # Column pattern for x-axis\n",
        "    hardness_pattern='Hardness (GPa)', # Column pattern for hardness\n",
        "    modulus_pattern='Modulus (GPa)',   # Column pattern for modulus\n",
        "    target_x_range=(100, 200, 50),     # (x_min, x_max, step) in nm\n",
        "    hardness_ylim=(0, 30),              # (min, max) for hardness y-axis\n",
        "    modulus_ylim=(0, 200)            # (min, max) for modulus y-axis\n",
        ")"
      ],
      "metadata": {
        "id": "RxQshL6UW0M9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/Y5Z3XI9tTmpVBkIZe7ec",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}